<apex:page >


    <title>MNIST in TensorFlow.js Layers API</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.15.1">
    </script>

    <body>
        <div class="tfjs-example-container">
            <section class='title-area'>
                <h1>TensorFlow.js: Digit Recognizer with Layers</h1>
                <p class='subtitle'>Train a model to recognize handwritten digits from the MNIST database using the tf.layers api.
                </p>
            </section>

            <section>
                <p class='section-head'>Description</p>
                <p>
                    This examples lets you train a handwritten digit recognizer using either a Convolutional Neural Network (also known as a
                    ConvNet or CNN) or a Fully Connected Neural Network (also known as a DenseNet).
                </p>
                <p>The MNIST dataset is used as training data.</p>
            </section>

            <section>
                <p class='section-head'>Training Parameters</p>
                <div>
                    <label>Model Type:</label>
                    <select id="model-type">
                        <option>ConvNet</option>
                        <option>DenseNet</option>
                    </select>
                </div>

                <div>
                    <label># of training epochs:</label>
                    <input id="train-epochs" value="3" />
                </div>

                <button id="train">Load Data and Train Model</button>
            </section>

            <section>
                <p class='section-head'>Training Progress</p>
                <p id="status"></p>
                <p id="message"></p>

                <div id="stats">
                    <div class="canvases">
                        <label id="loss-label"></label>
                        <div id="loss-canvas"></div>
                    </div>
                    <div class="canvases">
                        <label id="accuracy-label"></label>
                        <div id="accuracy-canvas"></div>
                    </div>
                </div>
            </section>

            <section>
                <p class='section-head'>Inference Examples</p>
                <div id="images"></div>
            </section>


        </div>
    </body>
    <script>
        window.onload = function () {

            async load() {
                const IMAGE_H = 224;
                const IMAGE_W = 224;
                const IMAGE_SIZE = IMAGE_H * IMAGE_W;
                const NUM_CLASSES = 10;
                const NUM_DATASET_ELEMENTS = 65000;

                const NUM_TRAIN_ELEMENTS = 55000;
                const NUM_TEST_ELEMENTS = NUM_DATASET_ELEMENTS - NUM_TRAIN_ELEMENTS;

                const MNIST_IMAGES_SPRITE_PATH =
                    'https://storage.googleapis.com/learnjs-data/model-builder/mnist_images.png';
                const MNIST_LABELS_PATH =
                    'https://storage.googleapis.com/learnjs-data/model-builder/mnist_labels_uint8';



                // Make a request for the MNIST sprited image.
                const img = new Image();
                const canvas = document.createElement('canvas');
                const ctx = canvas.getContext('2d');
                const imgRequest = new Promise((resolve, reject) => {
                    img.crossOrigin = '';
                    img.onload = () => {
                        img.width = img.naturalWidth;
                        img.height = img.naturalHeight;

                        const datasetBytesBuffer =
                            new ArrayBuffer(NUM_DATASET_ELEMENTS * IMAGE_SIZE * 4);

                        const chunkSize = 5000;
                        canvas.width = img.width;
                        canvas.height = chunkSize;

                        for (let i = 0; i < NUM_DATASET_ELEMENTS / chunkSize; i++) {
                            const datasetBytesView = new Float32Array(
                                datasetBytesBuffer, i * IMAGE_SIZE * chunkSize * 4,
                                IMAGE_SIZE * chunkSize);
                            ctx.drawImage(
                                img, 0, i * chunkSize, img.width, chunkSize, 0, 0, img.width,
                                chunkSize);

                            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);

                            for (let j = 0; j < imageData.data.length / 4; j++) {

                                datasetBytesView[j] = imageData.data[j * 4] / 255;
                            }
                        }
                        this.datasetImages = new Float32Array(datasetBytesBuffer);

                        resolve();
                    };
                    img.src = MNIST_IMAGES_SPRITE_PATH;
                });

                const labelsRequest = fetch(MNIST_LABELS_PATH);
                const [imgResponse, labelsResponse] =
                    await Promise.all([imgRequest, labelsRequest]);

                this.datasetLabels = new Uint8Array(await labelsResponse.arrayBuffer());

                // Slice the the images and labels into train and test sets.
                this.trainImages =
                    this.datasetImages.slice(0, IMAGE_SIZE * NUM_TRAIN_ELEMENTS);
                this.testImages = this.datasetImages.slice(IMAGE_SIZE * NUM_TRAIN_ELEMENTS);
                this.trainLabels =
                    this.datasetLabels.slice(0, NUM_CLASSES * NUM_TRAIN_ELEMENTS);
                this.testLabels =
                    this.datasetLabels.slice(NUM_CLASSES * NUM_TRAIN_ELEMENTS);
            }

            function getTrainData() {
                const xs = tf.tensor4d(
                    this.trainImages,
                    [this.trainImages.length / IMAGE_SIZE, IMAGE_H, IMAGE_W, 1]);
                const labels = tf.tensor2d(
                    this.trainLabels, [this.trainLabels.length / NUM_CLASSES, NUM_CLASSES]);
                return { xs, labels };
            }

            function getTestData(numExamples) {
                let xs = tf.tensor4d(
                    this.testImages,
                    [this.testImages.length / IMAGE_SIZE, IMAGE_H, IMAGE_W, 1]);
                let labels = tf.tensor2d(
                    this.testLabels, [this.testLabels.length / NUM_CLASSES, NUM_CLASSES]);

                if (numExamples != null) {
                    xs = xs.slice([0, 0, 0, 0], [numExamples, IMAGE_H, IMAGE_W, 1]);
                    labels = labels.slice([0, 0], [numExamples, NUM_CLASSES]);
                }
                return { xs, labels };
            }
        }
    }

    </script>
    <script>
    /*function createConvModel() {

            const model = tf.sequential();

            model.add(tf.layers.conv2d({
                inputShape: [IMAGE_H, IMAGE_W, 1],
                kernelSize: 3,
                filters: 16,
                activation: 'relu'
            }));

            model.add(tf.layers.maxPooling2d({ poolSize: 2, strides: 2 }));

            // Our third layer is another convolution, this time with 32 filters.
            model.add(tf.layers.conv2d({ kernelSize: 3, filters: 32, activation: 'relu' }));

            // Max pooling again.
            model.add(tf.layers.maxPooling2d({ poolSize: 2, strides: 2 }));

            // Add another conv2d layer.
            model.add(tf.layers.conv2d({ kernelSize: 3, filters: 32, activation: 'relu' }));
            model.add(tf.layers.flatten({}));

            model.add(tf.layers.dense({ units: 64, activation: 'relu' }));


            model.add(tf.layers.dense({ units: 10, activation: 'softmax' }));

            return model;
        }


        function createDenseModel() {
            const model = tf.sequential();
            model.add(tf.layers.flatten({ inputShape: [IMAGE_H, IMAGE_W, 1] }));
            model.add(tf.layers.dense({ units: 42, activation: 'relu' }));
            model.add(tf.layers.dense({ units: 10, activation: 'softmax' }));
            return model;
        }

        async function train(model, onIteration) {

            const optimizer = 'rmsprop';


            model.compile({
                optimizer,
                loss: 'categoricalCrossentropy',
                metrics: ['accuracy'],
            });

            const batchSize = 320;


            const validationSplit = 0.15;


            let trainBatchCount = 0;

            const trainData = data.getTrainData();
            const testData = data.getTestData();

            const totalNumBatches =
                Math.ceil(trainData.xs.shape[0] * (1 - validationSplit) / batchSize) *
                trainEpochs;

            let valAcc;
            await model.fit(trainData.xs, trainData.labels, {
                batchSize,
                validationSplit,
                epochs: trainEpochs,
                callbacks: {
                    onBatchEnd: async (batch, logs) => {
                        trainBatchCount++;

                        if (onIteration && batch % 10 === 0) {
                            onIteration('onBatchEnd', batch, logs);
                        }
                        await tf.nextFrame();
                    },
                    onEpochEnd: async (epoch, logs) => {
                        valAcc = logs.val_acc;

                        if (onIteration) {
                            onIteration('onEpochEnd', epoch, logs);
                        }
                        await tf.nextFrame();
                    }
                }
            });

            const testResult = model.evaluate(testData.xs, testData.labels);
            const testAccPercent = testResult[1].dataSync()[0] * 100;
            const finalValAccPercent = valAcc * 100;

        }

        async function showPredictions(model) {
            const testExamples = 100;
            const examples = data.getTestData(testExamples);


            tf.tidy(() => {
                const output = model.predict(examples.xs);

                const axis = 1;
                const labels = Array.from(examples.labels.argMax(axis).dataSync());
                const predictions = Array.from(output.argMax(axis).dataSync());

            });
        }

        function createModel() {
            let model;
            const modelType = ui.getModelTypeId();
            if (modelType === 'ConvNet') {
                model = createConvModel();
            } else if (modelType === 'DenseNet') {
                model = createDenseModel();
            } else {
                throw new Error(`Invalid model type: ${modelType}`);
            }
            return model;
        }

        let data;
        async function load() {
            data = new MnistData();
            await data.load();
        }
        async function xyz() {
            await load();

            const model = createModel();
            model.summary();

            await train(model, () => showPredictions(model));
        }*/
    </script>
</apex:page>